{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval / Rejection Model Training\n",
    "\n",
    "This notebook trains a classifier to predict whether a loan will be **approved** or **rejected** using the [mariosyahirhalimm/loan_prediction_dataset](https://huggingface.co/datasets/mariosyahirhalimm/loan_prediction_dataset) from Hugging Face.\n",
    "\n",
    "## Pipeline\n",
    "1. **Load** the dataset with `datasets.load_dataset`\n",
    "2. **Explore** columns, target, and missing values\n",
    "3. **Clean** the dataset (handle missing values, outliers, data quality issues)\n",
    "4. **Visualize** the dataset (distributions, correlations, feature relationships)\n",
    "5. **Preprocess** (encode categoricals, handle missing values, train/validation split)\n",
    "6. **Train** a classifier (Random Forest with n_estimators=100 trees, or XGBoost)\n",
    "7. **Evaluate** with confusion matrix visualizations and detailed metrics\n",
    "8. **Test** the model with sample predictions\n",
    "9. **Save** the model and preprocessing components\n",
    "\n",
    "**Note:** Random Forest and XGBoost use `n_estimators` (number of trees/boosting rounds), not epochs. The model trains 100 trees in a single pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cad767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Connection timed out while downloading.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Attempting to resume incomplete download (1.6 MB/7.8 MB, attempt 1)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install -q datasets pandas scikit-learn xgboost matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d10c8",
   "metadata": {},
   "source": [
    "## 2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huberttuyishime/Desktop/AgriFinConnect-Rwanda/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/huberttuyishime/Desktop/AgriFinConnect-Rwanda/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 614/614 [00:00<00:00, 16809.63 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "        num_rows: 614\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mariosyahirhalimm/loan_prediction_dataset\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead26f2",
   "metadata": {},
   "source": [
    "## 3. Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (614, 13)\n",
      "\n",
      "Columns: ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
      "\n",
      "First rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001011</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LP001014</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3036</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LP001018</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4006</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LP001020</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>12841</td>\n",
       "      <td>10968.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "5  LP001011   Male     Yes          2      Graduate           Yes   \n",
       "6  LP001013   Male     Yes          0  Not Graduate            No   \n",
       "7  LP001014   Male     Yes         3+      Graduate            No   \n",
       "8  LP001018   Male     Yes          2      Graduate            No   \n",
       "9  LP001020   Male     Yes          1      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "5             5417             4196.0       267.0             360.0   \n",
       "6             2333             1516.0        95.0             360.0   \n",
       "7             3036             2504.0       158.0             360.0   \n",
       "8             4006             1526.0       168.0             360.0   \n",
       "9            12841            10968.0       349.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  \n",
       "5             1.0         Urban           Y  \n",
       "6             1.0         Urban           Y  \n",
       "7             0.0     Semiurban           N  \n",
       "8             1.0         Urban           Y  \n",
       "9             1.0     Semiurban           N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use train split if present, else first split\n",
    "split_name = \"train\" if \"train\" in ds else list(ds.keys())[0]\n",
    "df = ds[split_name].to_pandas()\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c436858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: Loan_Status\n",
      "Loan_Status\n",
      "Y    422\n",
      "N    192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Info & missing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n",
      "None\n",
      "\n",
      "Missing per column:\n",
      "Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect target column (common names for loan status)\n",
    "target_candidates = [c for c in df.columns if \"loan\" in c.lower() and (\"status\" in c.lower() or \"approv\" in c.lower() or \"target\" in c.lower() or c.lower() == \"loan_status\")]\n",
    "if not target_candidates:\n",
    "    target_candidates = [c for c in df.columns if \"label\" in c.lower() or \"target\" in c.lower() or \"y\" == c.lower()]\n",
    "if not target_candidates:\n",
    "    # Fallback: last column is often the target\n",
    "    target_candidates = [df.columns[-1]]\n",
    "TARGET_COL = target_candidates[0]\n",
    "print(\"Target column:\", TARGET_COL)\n",
    "print(df[TARGET_COL].value_counts())\n",
    "print(\"\\nInfo & missing:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f760b",
   "metadata": {},
   "source": [
    "## 3. Clean the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baa758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: Handle missing values, outliers, and data quality issues\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"Before cleaning:\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Missing values:\\n{df_clean.isnull().sum()}\\n\")\n",
    "\n",
    "# 1. Handle missing values in numeric columns\n",
    "numeric_cols_clean = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
    "for col in numeric_cols_clean:\n",
    "    if col in df_clean.columns:\n",
    "        # Fill with median for numeric columns\n",
    "        median_val = df_clean[col].median()\n",
    "        df_clean[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Filled {col} missing values with median: {median_val:.2f}\")\n",
    "\n",
    "# 2. Handle missing values in categorical columns\n",
    "categorical_cols_clean = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\n",
    "for col in categorical_cols_clean:\n",
    "    if col in df_clean.columns:\n",
    "        # Fill with mode (most frequent value)\n",
    "        mode_val = df_clean[col].mode()[0] if len(df_clean[col].mode()) > 0 else 'Unknown'\n",
    "        df_clean[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"Filled {col} missing values with mode: {mode_val}\")\n",
    "\n",
    "# 3. Handle outliers in numeric columns (using IQR method)\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Cap outliers instead of removing (to preserve data size)\n",
    "    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "print(\"\\nOutlier handling (capping at 1.5*IQR):\")\n",
    "for col in ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']:\n",
    "    if col in df_clean.columns:\n",
    "        lower, upper = remove_outliers_iqr(df_clean, col)\n",
    "        print(f\"{col}: capped between {lower:.2f} and {upper:.2f}\")\n",
    "\n",
    "# 4. Standardize categorical values (remove extra spaces, convert to proper case)\n",
    "for col in categorical_cols_clean:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].astype(str).str.strip().str.title()\n",
    "\n",
    "# 5. Ensure Credit_History is binary (0 or 1)\n",
    "if 'Credit_History' in df_clean.columns:\n",
    "    df_clean['Credit_History'] = df_clean['Credit_History'].fillna(1.0)  # Assume good credit if missing\n",
    "    df_clean['Credit_History'] = df_clean['Credit_History'].astype(int)\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Missing values:\\n{df_clean.isnull().sum()}\")\n",
    "print(\"\\nDataset cleaned successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0726b52",
   "metadata": {},
   "source": [
    "## 4. Visualize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Use cleaned dataset\n",
    "df_viz = df_clean.copy()\n",
    "\n",
    "# 1. Target variable distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Target distribution\n",
    "axes[0, 0].pie(df_viz[TARGET_COL].value_counts(), labels=df_viz[TARGET_COL].value_counts().index, \n",
    "               autopct='%1.1f%%', startangle=90, colors=['#ff6b6b', '#51cf66'])\n",
    "axes[0, 0].set_title('Loan Status Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Gender distribution by loan status\n",
    "if 'Gender' in df_viz.columns:\n",
    "    pd.crosstab(df_viz['Gender'], df_viz[TARGET_COL]).plot(kind='bar', ax=axes[0, 1], color=['#ff6b6b', '#51cf66'])\n",
    "    axes[0, 1].set_title('Loan Status by Gender', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Gender')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].legend(['Rejected (N)', 'Approved (Y)'])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Married status distribution\n",
    "if 'Married' in df_viz.columns:\n",
    "    pd.crosstab(df_viz['Married'], df_viz[TARGET_COL]).plot(kind='bar', ax=axes[0, 2], color=['#ff6b6b', '#51cf66'])\n",
    "    axes[0, 2].set_title('Loan Status by Marital Status', fontsize=14, fontweight='bold')\n",
    "    axes[0, 2].set_xlabel('Married')\n",
    "    axes[0, 2].set_ylabel('Count')\n",
    "    axes[0, 2].legend(['Rejected (N)', 'Approved (Y)'])\n",
    "    axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Applicant Income distribution\n",
    "if 'ApplicantIncome' in df_viz.columns:\n",
    "    axes[1, 0].hist([df_viz[df_viz[TARGET_COL]=='Y']['ApplicantIncome'], \n",
    "                     df_viz[df_viz[TARGET_COL]=='N']['ApplicantIncome']], \n",
    "                    bins=30, color=['#51cf66', '#ff6b6b'], alpha=0.7, label=['Approved', 'Rejected'])\n",
    "    axes[1, 0].set_title('Applicant Income Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Applicant Income')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# Loan Amount distribution\n",
    "if 'LoanAmount' in df_viz.columns:\n",
    "    axes[1, 1].hist([df_viz[df_viz[TARGET_COL]=='Y']['LoanAmount'], \n",
    "                     df_viz[df_viz[TARGET_COL]=='N']['LoanAmount']], \n",
    "                    bins=30, color=['#51cf66', '#ff6b6b'], alpha=0.7, label=['Approved', 'Rejected'])\n",
    "    axes[1, 1].set_title('Loan Amount Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Loan Amount')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "# Credit History impact\n",
    "if 'Credit_History' in df_viz.columns:\n",
    "    pd.crosstab(df_viz['Credit_History'], df_viz[TARGET_COL]).plot(kind='bar', ax=axes[1, 2], color=['#ff6b6b', '#51cf66'])\n",
    "    axes[1, 2].set_title('Loan Status by Credit History', fontsize=14, fontweight='bold')\n",
    "    axes[1, 2].set_xlabel('Credit History (0=No, 1=Yes)')\n",
    "    axes[1, 2].set_ylabel('Count')\n",
    "    axes[1, 2].legend(['Rejected (N)', 'Approved (Y)'])\n",
    "    axes[1, 2].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ee51f",
   "metadata": {},
   "source": [
    "### 4.1. Additional visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualizations: Correlation heatmap and feature importance preview\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Correlation heatmap for numeric features\n",
    "numeric_for_corr = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
    "numeric_df = df_viz[numeric_for_corr + [TARGET_COL]].copy()\n",
    "# Encode target for correlation\n",
    "numeric_df[TARGET_COL + '_encoded'] = (numeric_df[TARGET_COL] == 'Y').astype(int)\n",
    "corr_cols = numeric_for_corr + [TARGET_COL + '_encoded']\n",
    "corr_matrix = numeric_df[corr_cols].corr()\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=axes[0])\n",
    "axes[0].set_title('Correlation Heatmap (Numeric Features)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Property Area distribution\n",
    "if 'Property_Area' in df_viz.columns:\n",
    "    pd.crosstab(df_viz['Property_Area'], df_viz[TARGET_COL]).plot(kind='bar', ax=axes[1], color=['#ff6b6b', '#51cf66'])\n",
    "    axes[1].set_title('Loan Status by Property Area', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Property Area')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(['Rejected (N)', 'Approved (Y)'])\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef832a9",
   "metadata": {},
   "source": [
    "## 5. Preprocess and prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['N' 'Y'] -> [0 1]\n",
      "Numeric: ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
      "Categorical: ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\n",
      "\n",
      "Train size: 491 Val size: 123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Use cleaned dataset\n",
    "df_work = df_clean.copy()\n",
    "\n",
    "# Drop ID-like columns if present\n",
    "id_cols = [c for c in df_work.columns if \"id\" in c.lower() and c != TARGET_COL]\n",
    "df_work = df_work.drop(columns=id_cols, errors=\"ignore\")\n",
    "\n",
    "X = df_work.drop(columns=[TARGET_COL])\n",
    "y_raw = df_work[TARGET_COL]\n",
    "\n",
    "# Encode target: binary (approved=1, rejected=0)\n",
    "le_target = LabelEncoder()\n",
    "y = le_target.fit_transform(y_raw.astype(str))\n",
    "print(\"Target classes:\", le_target.classes_, \"->\", np.unique(y))\n",
    "\n",
    "# Identify numeric vs categorical\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "print(\"Numeric:\", numeric_cols)\n",
    "print(\"Categorical:\", cat_cols)\n",
    "\n",
    "# Fill missing: numeric -> median, categorical -> most_frequent\n",
    "if numeric_cols:\n",
    "    for c in numeric_cols:\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "    X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].fillna(X[c].mode().iloc[0] if len(X[c].mode()) else \"Unknown\")\n",
    "    X[c] = LabelEncoder().fit_transform(X[c].astype(str))\n",
    "\n",
    "feature_cols = numeric_cols + cat_cols\n",
    "X = X[feature_cols]\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "print(\"\\nTrain size:\", X_train.shape[0], \"Val size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbd0db",
   "metadata": {},
   "source": [
    "## 6. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e38399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8373983739837398\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.85      0.58      0.69        38\n",
      "           Y       0.84      0.95      0.89        85\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.84      0.77      0.79       123\n",
      "weighted avg       0.84      0.84      0.83       123\n",
      "\n",
      "Confusion matrix:\n",
      "[[22 16]\n",
      " [ 4 81]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Note: Random Forest doesn't use \"epochs\" - it uses n_estimators (number of trees)\n",
    "# n_estimators=100 means 100 decision trees will be trained\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "print(\"Note: Random Forest uses n_estimators (number of trees), not epochs.\")\n",
    "print(f\"Training with n_estimators=100 trees, max_depth=10\\n\")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=le_target.classes_.tolist()))\n",
    "print(\"\\nConfusion matrix:\")\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca6de9",
   "metadata": {},
   "source": [
    "## 7. (Optional) XGBoost alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55609885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8048780487804879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.68      0.71      0.69        38\n",
      "           Y       0.87      0.85      0.86        85\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.77      0.78      0.77       123\n",
      "weighted avg       0.81      0.80      0.81       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huberttuyishime/Desktop/AgriFinConnect-Rwanda/venv/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [11:00:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "    # Note: XGBoost also uses n_estimators (number of boosting rounds), not epochs\n",
    "    print(\"Training XGBoost Classifier...\")\n",
    "    print(\"Note: XGBoost uses n_estimators (boosting rounds), not epochs.\")\n",
    "    print(f\"Training with n_estimators=100 boosting rounds, max_depth=6\\n\")\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=6, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb_model.predict(X_val)\n",
    "    print(\"XGBoost Accuracy:\", accuracy_score(y_val, y_pred_xgb))\n",
    "    print(classification_report(y_val, y_pred_xgb, target_names=le_target.classes_.tolist()))\n",
    "    \n",
    "    # Visualize XGBoost confusion matrix\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    cm_xgb = confusion_matrix(y_val, y_pred_xgb)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "    disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=le_target.classes_)\n",
    "    disp_xgb.plot(ax=ax, cmap='Greens', values_format='d')\n",
    "    ax.set_title('Confusion Matrix - XGBoost', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Using Random Forest only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8ffaf",
   "metadata": {},
   "source": [
    "## 8. Evaluate model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364e23b",
   "metadata": {},
   "source": [
    "### 8.1. Feature importance analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Create confusion matrix visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Standard confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le_target.classes_)\n",
    "disp.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title('Confusion Matrix - Random Forest', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Normalized confusion matrix (percentages)\n",
    "cm_normalized = confusion_matrix(y_val, y_pred, normalize='true')\n",
    "disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=le_target.classes_)\n",
    "disp_norm.plot(ax=axes[1], cmap='Blues', values_format='.2%')\n",
    "axes[1].set_title('Normalized Confusion Matrix (Percentages)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nDetailed Performance Metrics:\")\n",
    "print(f\"True Negatives (TN): {tn} - Correctly predicted Rejected loans\")\n",
    "print(f\"False Positives (FP): {fp} - Incorrectly predicted as Approved (Type I Error)\")\n",
    "print(f\"False Negatives (FN): {fn} - Incorrectly predicted as Rejected (Type II Error)\")\n",
    "print(f\"True Positives (TP): {tp} - Correctly predicted Approved loans\")\n",
    "print(f\"\\nSensitivity (Recall/TPR): {tp/(tp+fn):.3f} - Ability to detect approved loans\")\n",
    "print(f\"Specificity (TNR): {tn/(tn+fp):.3f} - Ability to detect rejected loans\")\n",
    "print(f\"Precision: {tp/(tp+fp):.3f} - Accuracy of approved predictions\")\n",
    "print(f\"F1-Score: {2*tp/(2*tp+fp+fn):.3f} - Harmonic mean of precision and recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b84877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional testing: Feature importance visualization\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
    "plt.title('Feature Importance - Random Forest Model', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head(5).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7312382",
   "metadata": {},
   "source": [
    "## 9. Test the model with sample predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with sample loan applications\n",
    "import pandas as pd\n",
    "\n",
    "def predict_loan_approval(model, scaler, le_target, feature_cols, applicant_data):\n",
    "    \"\"\"\n",
    "    Predict loan approval for a new applicant.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained classifier\n",
    "    - scaler: Fitted StandardScaler\n",
    "    - le_target: Fitted LabelEncoder for target\n",
    "    - feature_cols: List of feature column names in order\n",
    "    - applicant_data: Dictionary with applicant information\n",
    "    \n",
    "    Returns:\n",
    "    - prediction: 'Y' (Approved) or 'N' (Rejected)\n",
    "    - probability: Probability of approval\n",
    "    \"\"\"\n",
    "    # Create DataFrame from applicant data\n",
    "    df_applicant = pd.DataFrame([applicant_data])\n",
    "    \n",
    "    # Prepare features in the same order as training\n",
    "    X_applicant = pd.DataFrame(columns=feature_cols)\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        if col in df_applicant.columns:\n",
    "            X_applicant[col] = df_applicant[col]\n",
    "        else:\n",
    "            # Fill missing with default values\n",
    "            if col in numeric_cols:\n",
    "                X_applicant[col] = df_clean[col].median()\n",
    "            else:\n",
    "                X_applicant[col] = df_clean[col].mode()[0] if len(df_clean[col].mode()) > 0 else 'Unknown'\n",
    "    \n",
    "    # Encode categorical variables (using the same encoding as training)\n",
    "    for col in cat_cols:\n",
    "        if col in X_applicant.columns:\n",
    "            # Use the same label encoders (in practice, save and load them)\n",
    "            le_temp = LabelEncoder()\n",
    "            le_temp.fit(df_clean[col].astype(str))\n",
    "            X_applicant[col] = le_temp.transform(X_applicant[col].astype(str))\n",
    "    \n",
    "    # Scale features\n",
    "    X_applicant_scaled = scaler.transform(X_applicant)\n",
    "    \n",
    "    # Predict\n",
    "    prediction_encoded = model.predict(X_applicant_scaled)[0]\n",
    "    probability = model.predict_proba(X_applicant_scaled)[0]\n",
    "    \n",
    "    # Decode prediction\n",
    "    prediction = le_target.inverse_transform([prediction_encoded])[0]\n",
    "    prob_approved = probability[1] if prediction_encoded == 1 else probability[0]\n",
    "    \n",
    "    return prediction, prob_approved\n",
    "\n",
    "# Test cases\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTING THE LOAN APPROVAL MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test Case 1: High-income applicant with good credit\n",
    "test_case_1 = {\n",
    "    'Gender': 'Male',\n",
    "    'Married': 'Yes',\n",
    "    'Dependents': '0',\n",
    "    'Education': 'Graduate',\n",
    "    'Self_Employed': 'No',\n",
    "    'ApplicantIncome': 15000,\n",
    "    'CoapplicantIncome': 5000,\n",
    "    'LoanAmount': 200,\n",
    "    'Loan_Amount_Term': 360,\n",
    "    'Credit_History': 1,\n",
    "    'Property_Area': 'Urban'\n",
    "}\n",
    "\n",
    "pred1, prob1 = predict_loan_approval(model, scaler, le_target, feature_cols, test_case_1)\n",
    "print(\"\\nTest Case 1: High-income applicant with good credit\")\n",
    "print(f\"  Prediction: {'APPROVED' if pred1 == 'Y' else 'REJECTED'}\")\n",
    "print(f\"  Confidence: {prob1*100:.2f}%\")\n",
    "print(f\"  Details: Income={test_case_1['ApplicantIncome']}, Credit History={test_case_1['Credit_History']}\")\n",
    "\n",
    "# Test Case 2: Low-income applicant with poor credit\n",
    "test_case_2 = {\n",
    "    'Gender': 'Female',\n",
    "    'Married': 'No',\n",
    "    'Dependents': '2',\n",
    "    'Education': 'Not Graduate',\n",
    "    'Self_Employed': 'Yes',\n",
    "    'ApplicantIncome': 2000,\n",
    "    'CoapplicantIncome': 0,\n",
    "    'LoanAmount': 500,\n",
    "    'Loan_Amount_Term': 360,\n",
    "    'Credit_History': 0,\n",
    "    'Property_Area': 'Rural'\n",
    "}\n",
    "\n",
    "pred2, prob2 = predict_loan_approval(model, scaler, le_target, feature_cols, test_case_2)\n",
    "print(\"\\nTest Case 2: Low-income applicant with poor credit\")\n",
    "print(f\"  Prediction: {'APPROVED' if pred2 == 'Y' else 'REJECTED'}\")\n",
    "print(f\"  Confidence: {prob2*100:.2f}%\")\n",
    "print(f\"  Details: Income={test_case_2['ApplicantIncome']}, Credit History={test_case_2['Credit_History']}\")\n",
    "\n",
    "# Test Case 3: Medium-income applicant with good credit\n",
    "test_case_3 = {\n",
    "    'Gender': 'Male',\n",
    "    'Married': 'Yes',\n",
    "    'Dependents': '1',\n",
    "    'Education': 'Graduate',\n",
    "    'Self_Employed': 'No',\n",
    "    'ApplicantIncome': 6000,\n",
    "    'CoapplicantIncome': 2000,\n",
    "    'LoanAmount': 150,\n",
    "    'Loan_Amount_Term': 360,\n",
    "    'Credit_History': 1,\n",
    "    'Property_Area': 'Semiurban'\n",
    "}\n",
    "\n",
    "pred3, prob3 = predict_loan_approval(model, scaler, le_target, feature_cols, test_case_3)\n",
    "print(\"\\nTest Case 3: Medium-income applicant with good credit\")\n",
    "print(f\"  Prediction: {'APPROVED' if pred3 == 'Y' else 'REJECTED'}\")\n",
    "print(f\"  Confidence: {prob3*100:.2f}%\")\n",
    "print(f\"  Details: Income={test_case_3['ApplicantIncome']}, Credit History={test_case_3['Credit_History']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Model testing completed!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471bb26",
   "metadata": {},
   "source": [
    "## 10. Save the model and encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3b969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to loan_approval_model\n",
      "Files: [PosixPath('loan_approval_model/feature_columns.joblib'), PosixPath('loan_approval_model/scaler.joblib'), PosixPath('loan_approval_model/label_encoder.joblib'), PosixPath('loan_approval_model/loan_classifier.joblib')]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\"loan_approval_model\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(model, OUTPUT_DIR / \"loan_classifier.joblib\")\n",
    "joblib.dump(le_target, OUTPUT_DIR / \"label_encoder.joblib\")\n",
    "joblib.dump(scaler, OUTPUT_DIR / \"scaler.joblib\")\n",
    "joblib.dump(feature_cols, OUTPUT_DIR / \"feature_columns.joblib\")\n",
    "\n",
    "print(\"Saved to\", OUTPUT_DIR)\n",
    "print(\"Files:\", list(OUTPUT_DIR.iterdir()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
