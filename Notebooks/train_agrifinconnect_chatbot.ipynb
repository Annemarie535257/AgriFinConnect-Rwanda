{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd0766bb",
      "metadata": {},
      "source": [
        "# AgriFinConnect-Rwanda: Multilingual Loan Chatbot Training\n",
        "\n",
        "This notebook trains a **Llama-based** AI chatbot for AgriFinConnect-Rwanda that:\n",
        "- **Guides users through loan applications**\n",
        "- **Explains loan terms and repayment schedules**\n",
        "- **Provides basic financial literacy support**\n",
        "- **Responds in Kinyarwanda, English, and French**\n",
        "\n",
        "## Pipeline Overview\n",
        "1. **Load** the Bitext mortgage/loans dataset (English)\n",
        "2. **Translate** to Kinyarwanda and French using NLLB (No Language Left Behind)\n",
        "3. **Combine** multilingual dataset (EN + RW + FR)\n",
        "4. **Fine-tune** Llama with LoRA/PEFT on the combined data\n",
        "\n",
        "## Requirements\n",
        "- GPU recommended (Colab T4/V100 or local CUDA GPU)\n",
        "- Hugging Face account (for Llama model access - accept Meta's license at https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c9d432",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d57bb2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run once, restart kernel if needed)\n",
        "!pip install -q transformers datasets accelerate peft bitsandbytes pandas torch sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ac596da1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: False\n"
          ]
        }
      ],
      "source": [
        "# Imports and configuration\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration - adjust these as needed\n",
        "DATA_PATH = \"Bitext-mortgage-loans-llm-chatbot-training-dataset/bitext-mortgage-loans-llm-chatbot-training-dataset.csv\"\n",
        "OUTPUT_DIR = \"agrifinconnect_multilingual_dataset\"\n",
        "TRANSLATED_DATA_PATH = \"agrifinconnect_multilingual_dataset/multilingual_loan_dataset.csv\"\n",
        "\n",
        "# Translation: use SUBSET_SIZE for quick testing, None for full dataset\n",
        "SUBSET_SIZE = 2000  # Set to None to translate full ~37K rows (takes several hours)\n",
        "TRANSLATION_BATCH_SIZE = 8\n",
        "NLLB_MODEL = \"facebook/nllb-200-distilled-600M\"  # Lighter; use nllb-200-distilled-1.3B for better quality\n",
        "\n",
        "# Training\n",
        "LLAMA_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"  # Requires HF login + Meta license\n",
        "OUTPUT_MODEL_DIR = \"agrifinconnect-loan-chatbot\"\n",
        "TRAINING_EPOCHS = 2\n",
        "LEARNING_RATE = 2e-5\n",
        "MAX_SEQ_LENGTH = 1024\n",
        "\n",
        "# Create output directory\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0112844c",
      "metadata": {},
      "source": [
        "## 2. Load Original Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4bc60134",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 36778 rows\n",
            "['system_prompt', 'instruction', 'intent', 'category', 'tags', 'response']\n",
            "Using subset of 2000 rows for translation\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>system_prompt</th>\n",
              "      <th>instruction</th>\n",
              "      <th>intent</th>\n",
              "      <th>category</th>\n",
              "      <th>tags</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You are an expert in customer support for mort...</td>\n",
              "      <td>i got to speak with a fucking operator</td>\n",
              "      <td>human_agent</td>\n",
              "      <td>CONTACT</td>\n",
              "      <td>BLQW</td>\n",
              "      <td>I apologize for any frustration or confusion y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You are an expert in customer support for mort...</td>\n",
              "      <td>I want to take out a home loan with my partner</td>\n",
              "      <td>apply_for_joint_loan</td>\n",
              "      <td>LOAN_APPLICATION</td>\n",
              "      <td>BL</td>\n",
              "      <td>Unquestionably! Applying for a home loan with ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       system_prompt  \\\n",
              "0  You are an expert in customer support for mort...   \n",
              "1  You are an expert in customer support for mort...   \n",
              "\n",
              "                                      instruction                intent  \\\n",
              "0          i got to speak with a fucking operator           human_agent   \n",
              "1  I want to take out a home loan with my partner  apply_for_joint_loan   \n",
              "\n",
              "           category  tags                                           response  \n",
              "0           CONTACT  BLQW  I apologize for any frustration or confusion y...  \n",
              "1  LOAN_APPLICATION    BL  Unquestionably! Applying for a home loan with ...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the Bitext mortgage/loans dataset\n",
        "df = pd.read_csv(DATA_PATH, on_bad_lines='skip')\n",
        "print(f\"Loaded {len(df)} rows\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Use subset for faster iteration (optional)\n",
        "if SUBSET_SIZE is not None:\n",
        "    df = df.sample(n=min(SUBSET_SIZE, len(df)), random_state=42).reset_index(drop=True)\n",
        "    print(f\"Using subset of {len(df)} rows for translation\")\n",
        "\n",
        "# Keep only needed columns\n",
        "df = df[['system_prompt', 'instruction', 'intent', 'category', 'tags', 'response']]\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad7129a",
      "metadata": {},
      "source": [
        "## 3. Translate Dataset to Kinyarwanda and French\n",
        "\n",
        "Using **NLLB (No Language Left Behind)** from Meta - supports 200+ languages including Kinyarwanda (`kin_Latn`) and French (`fra_Latn`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "40622a83",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading NLLB translation model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|██████████| 512/512 [00:01<00:00, 287.98it/s, Materializing param=model.shared.weight]                                   \n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLLB model loaded.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load NLLB translation model\n",
        "print(\"Loading NLLB translation model...\")\n",
        "translation_tokenizer = AutoTokenizer.from_pretrained(NLLB_MODEL)\n",
        "translation_model = AutoModelForSeq2SeqLM.from_pretrained(NLLB_MODEL)\n",
        "if torch.cuda.is_available():\n",
        "    translation_model = translation_model.cuda()\n",
        "translation_model.eval()\n",
        "print(\"NLLB model loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "411e8d15",
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_batch(texts, src_lang=\"eng_Latn\", tgt_lang=\"fra_Latn\", max_length=512):\n",
        "    \"\"\"Translate a batch of texts using NLLB.\"\"\"\n",
        "    if not texts or all(not t or (isinstance(t, float) and pd.isna(t)) for t in texts):\n",
        "        return [\"\"] * len(texts)\n",
        "    \n",
        "    # Clean texts\n",
        "    texts = [str(t).strip() if pd.notna(t) and str(t).strip() else \"\" for t in texts]\n",
        "    \n",
        "    translation_tokenizer.src_lang = src_lang\n",
        "    forced_bos_id = translation_tokenizer.convert_tokens_to_ids(tgt_lang)\n",
        "    \n",
        "    inputs = translation_tokenizer(\n",
        "        texts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = translation_model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=forced_bos_id,\n",
        "            max_length=max_length,\n",
        "            num_beams=2,\n",
        "        )\n",
        "    \n",
        "    return translation_tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "96ba8592",
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_column(df, column, tgt_lang, batch_size=TRANSLATION_BATCH_SIZE):\n",
        "    \"\"\"Translate a column in batches.\"\"\"\n",
        "    results = []\n",
        "    n = len(df)\n",
        "    for i in range(0, n, batch_size):\n",
        "        batch = df[column].iloc[i:i + batch_size].tolist()\n",
        "        translated = translate_batch(batch, src_lang=\"eng_Latn\", tgt_lang=tgt_lang)\n",
        "        results.extend(translated)\n",
        "        if (i + batch_size) % 100 == 0 or i + batch_size >= n:\n",
        "            print(f\"  Translated {min(i + batch_size, n)}/{n} rows...\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e6bc0d01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translating to Kinyarwanda...\n",
            "  Translated 200/2000 rows...\n",
            "  Translated 400/2000 rows...\n",
            "  Translated 600/2000 rows...\n",
            "  Translated 800/2000 rows...\n",
            "  Translated 1000/2000 rows...\n",
            "  Translated 1200/2000 rows...\n",
            "  Translated 1400/2000 rows...\n",
            "  Translated 1600/2000 rows...\n",
            "  Translated 1800/2000 rows...\n",
            "  Translated 2000/2000 rows...\n",
            "  Translated 200/2000 rows...\n",
            "  Translated 400/2000 rows...\n",
            "  Translated 600/2000 rows...\n",
            "  Translated 800/2000 rows...\n",
            "  Translated 1000/2000 rows...\n",
            "  Translated 1200/2000 rows...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTranslating to Kinyarwanda...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33minstruction_kin\u001b[39m\u001b[33m\"\u001b[39m] = translate_column(df, \u001b[33m\"\u001b[39m\u001b[33minstruction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkin_Latn\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mresponse_kin\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtranslate_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkin_Latn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKinyarwanda translation done.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtranslate_column\u001b[39m\u001b[34m(df, column, tgt_lang, batch_size)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, n, batch_size):\n\u001b[32m      6\u001b[39m     batch = df[column].iloc[i:i + batch_size].tolist()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     translated = \u001b[43mtranslate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_lang\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meng_Latn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     results.extend(translated)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (i + batch_size) % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i + batch_size >= n:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtranslate_batch\u001b[39m\u001b[34m(texts, src_lang, tgt_lang, max_length)\u001b[39m\n\u001b[32m     21\u001b[39m     inputs = {k: v.cuda() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs.items()}\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     outputs = \u001b[43mtranslation_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforced_bos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforced_bos_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m translation_tokenizer.batch_decode(outputs, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:124\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# pyrefly: ignore [bad-context-manager]\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2669\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2666\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2668\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2669\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2670\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2671\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2677\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3362\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3360\u001b[39m     flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3361\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3362\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3363\u001b[39m prefill_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3365\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:1106\u001b[39m, in \u001b[36mM2M100ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1102\u001b[39m         decoder_input_ids = shift_tokens_right(\n\u001b[32m   1103\u001b[39m             labels, \u001b[38;5;28mself\u001b[39m.config.pad_token_id, \u001b[38;5;28mself\u001b[39m.config.decoder_start_token_id\n\u001b[32m   1104\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m lm_logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m])\n\u001b[32m   1123\u001b[39m masked_lm_loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:997\u001b[39m, in \u001b[36mM2M100Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[39m\n\u001b[32m    990\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m    991\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m    992\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    993\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    994\u001b[39m     )\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_values, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:869\u001b[39m, in \u001b[36mM2M100Decoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[39m\n\u001b[32m    865\u001b[39m skip_the_layer = \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mand\u001b[39;00m dropout_probability < \u001b[38;5;28mself\u001b[39m.layerdrop\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_the_layer \u001b[38;5;129;01mor\u001b[39;00m synced_gpus:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# under fsdp or deepspeed zero3 all gpus must run in sync\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skip_the_layer:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         logger.warning_once(message)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:479\u001b[39m, in \u001b[36mM2M100DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, use_cache, cache_position)\u001b[39m\n\u001b[32m    476\u001b[39m residual = hidden_states\n\u001b[32m    477\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.encoder_attn_layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m hidden_states, cross_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    487\u001b[39m hidden_states = residual + hidden_states\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:320\u001b[39m, in \u001b[36mM2M100Attention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, past_key_values, attention_mask, output_attentions, cache_position, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    318\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m attn_output = attn_output.reshape(bsz, tgt_len, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    333\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.out_proj(attn_output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Desktop\\ALU\\AgriFinConnect-Rwanda\\venv\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:92\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask.dtype != torch.bool:\n\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m# Convert to boolean type, making sdpa to force call FlashAttentionScore to improve performance.\u001b[39;00m\n\u001b[32m     90\u001b[39m         attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msdpa_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Translate to Kinyarwanda (kin_Latn)\n",
        "print(\"Translating to Kinyarwanda...\")\n",
        "df[\"instruction_kin\"] = translate_column(df, \"instruction\", \"kin_Latn\")\n",
        "df[\"response_kin\"] = translate_column(df, \"response\", \"kin_Latn\")\n",
        "print(\"Kinyarwanda translation done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a9fa67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Translate to French (fra_Latn)\n",
        "print(\"Translating to French...\")\n",
        "df[\"instruction_fra\"] = translate_column(df, \"instruction\", \"fra_Latn\")\n",
        "df[\"response_fra\"] = translate_column(df, \"response\", \"fra_Latn\")\n",
        "print(\"French translation done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d333be80",
      "metadata": {},
      "source": [
        "**Optional:** To skip translation (if you already ran it once and saved), run the cell below instead of cells 10-11:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f61159f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# SKIP TRANSLATION: Load pre-translated data (run this instead of translation + combine cells)\n",
        "# df_multilingual = pd.read_csv(TRANSLATED_DATA_PATH)\n",
        "# print(f\"Loaded {len(df_multilingual)} rows. Skip to '5. Format Dataset for Llama Fine-Tuning'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0997d2a",
      "metadata": {},
      "source": [
        "## 4. Combine Multilingual Dataset\n",
        "\n",
        "Create one dataset with English, Kinyarwanda, and French instruction-response pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9b76ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build multilingual dataset: EN + Kinyarwanda + French\n",
        "SYSTEM_PROMPT = \"You are an expert in customer support for mortgage and loans. Guide users through loan applications, explain loan terms and repayment schedules, and provide financial literacy support. Respond in the same language as the user (English, Kinyarwanda, or French).\"\n",
        "\n",
        "records = []\n",
        "\n",
        "# English\n",
        "for _, row in df.iterrows():\n",
        "    records.append({\n",
        "        \"language\": \"en\",\n",
        "        \"system_prompt\": SYSTEM_PROMPT,\n",
        "        \"instruction\": row[\"instruction\"],\n",
        "        \"response\": row[\"response\"],\n",
        "        \"intent\": row[\"intent\"],\n",
        "        \"category\": row[\"category\"],\n",
        "    })\n",
        "\n",
        "# Kinyarwanda\n",
        "for _, row in df.iterrows():\n",
        "    records.append({\n",
        "        \"language\": \"kin\",\n",
        "        \"system_prompt\": SYSTEM_PROMPT,\n",
        "        \"instruction\": row[\"instruction_kin\"],\n",
        "        \"response\": row[\"response_kin\"],\n",
        "        \"intent\": row[\"intent\"],\n",
        "        \"category\": row[\"category\"],\n",
        "    })\n",
        "\n",
        "# French\n",
        "for _, row in df.iterrows():\n",
        "    records.append({\n",
        "        \"language\": \"fr\",\n",
        "        \"system_prompt\": SYSTEM_PROMPT,\n",
        "        \"instruction\": row[\"instruction_fra\"],\n",
        "        \"response\": row[\"response_fra\"],\n",
        "        \"intent\": row[\"intent\"],\n",
        "        \"category\": row[\"category\"],\n",
        "    })\n",
        "\n",
        "df_multilingual = pd.DataFrame(records)\n",
        "df_multilingual.to_csv(TRANSLATED_DATA_PATH, index=False)\n",
        "print(f\"Multilingual dataset: {len(df_multilingual)} rows (EN: {len(df)}, KIN: {len(df)}, FR: {len(df)})\")\n",
        "df_multilingual.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acbb8f42",
      "metadata": {},
      "source": [
        "## 5. Format Dataset for Llama Fine-Tuning\n",
        "\n",
        "Convert to chat format compatible with Llama 3.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cadd36f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def format_chat(example):\n",
        "    \"\"\"Format as Llama 3.2 chat: <|begin_of_text|><|start_header_id|>system<|end_header_id|>...\"\"\"\n",
        "    return {\n",
        "        \"text\": f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{example['system_prompt']}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{example['instruction']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{example['response']}<|eot_id|>\"\n",
        "    }\n",
        "\n",
        "# Convert to HuggingFace Dataset\n",
        "hf_dataset = Dataset.from_pandas(df_multilingual[[\"system_prompt\", \"instruction\", \"response\"]])\n",
        "hf_dataset = hf_dataset.map(format_chat, remove_columns=[\"system_prompt\", \"instruction\", \"response\"])\n",
        "print(f\"Dataset size: {len(hf_dataset)}\")\n",
        "print(\"Sample formatted text (first 500 chars):\")\n",
        "print(hf_dataset[0][\"text\"][:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f123a3",
      "metadata": {},
      "source": [
        "## 6. Load Llama Model and Tokenizer\n",
        "\n",
        "**Note:** You must log in to Hugging Face and accept Meta's Llama license:\n",
        "1. `huggingface-cli login`\n",
        "2. Visit https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct and accept the license"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c19fcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# 4-bit quantization for memory efficiency (fits on ~8GB GPU)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "print(\"Loading Llama model and tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA_MODEL, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLAMA_MODEL,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "print(\"Model loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "947fa18b",
      "metadata": {},
      "source": [
        "## 7. Configure LoRA and Prepare for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f370ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Prepare model for k-bit training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ee8c9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_SEQ_LENGTH,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_dataset = hf_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        "    desc=\"Tokenizing\",\n",
        ")\n",
        "\n",
        "# Set labels for causal LM (labels = input_ids, with -100 for padding)\n",
        "def set_labels(examples):\n",
        "    examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
        "    return examples\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(set_labels, batched=True, desc=\"Setting labels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab8d7e1",
      "metadata": {},
      "source": [
        "## 8. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa85b53f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# Set pad token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_MODEL_DIR,\n",
        "    num_train_epochs=TRAINING_EPOCHS,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb681ce7",
      "metadata": {},
      "source": [
        "## 9. Save Model and Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f14b27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the fine-tuned model\n",
        "trainer.save_model(OUTPUT_MODEL_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_MODEL_DIR)\n",
        "print(f\"Model saved to {OUTPUT_MODEL_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbba585",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick inference test\n",
        "model.eval()\n",
        "def chat(prompt, max_new_tokens=256):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=True, temperature=0.7)\n",
        "    return tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "# Test in English\n",
        "print(\"--- English ---\")\n",
        "print(chat(\"How do I apply for a loan?\"))\n",
        "\n",
        "# Test in Kinyarwanda (if you have Kinyarwanda samples)\n",
        "print(\"\\n--- Kinyarwanda ---\")\n",
        "print(chat(\"Nte nshobora gusaba icyangombwa?\"))\n",
        "\n",
        "# Test in French\n",
        "print(\"\\n--- French ---\")\n",
        "print(chat(\"Comment puis-je demander un prêt?\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
